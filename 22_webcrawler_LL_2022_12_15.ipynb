{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKwP6xqo6b8d"
   },
   "outputs": [],
   "source": [
    "# https://blog.devgenius.io/how-to-build-a-scraping-tool-for-linkedin-in-7-minutes-tool-data-science-csv-selenium-beautifulsoup-python-a673f12ac579\n",
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QqvrsGn36KDD"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job name: Machine learning\n"
     ]
    }
   ],
   "source": [
    "job_name = input(\"Enter the job name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job location: Washington\n"
     ]
    }
   ],
   "source": [
    "country_name =input(\"Enter the job location: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name.split(\" \")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "FqYsJGMi6ops",
    "outputId": "ab5777d2-c7fd-457f-a629-592c36ae2390"
   },
   "outputs": [],
   "source": [
    "# job_name = \"Data Scientist\"\n",
    "# country_name = \"United States\"\n",
    "\n",
    "job_url =\"\";\n",
    "for item in job_name.split(\" \"):# Data and Scientist\n",
    "    if item != job_name.split(\" \")[-1]: # \n",
    "        job_url = job_url + item + \"%20\"\n",
    "    else:\n",
    "        job_url = job_url + item\n",
    "\n",
    "country_url =\"\";\n",
    "for item in country_name.split(\" \"):\n",
    "    if item != country_name.split(\" \")[-1]:\n",
    "        country_url = country_url + item + \"%20\"\n",
    "    else:\n",
    "        country_url = country_url + item\n",
    "\n",
    "url = \"https://www.linkedin.com/jobs/search?keywords={0}&location={1}&geoId=103644278&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\".format(job_url,country_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "G9weroyz-0LX",
    "outputId": "189a004a-12f9-4514-9906-4c2c850c947d"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from selenium import webdriver\n",
    "# def main():\n",
    "#     a = webdriver.Chrome()\n",
    "#     a.get('https://www.google.com')\n",
    "#     time.sleep(5)\n",
    "#     a.quit()\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "T3crarDT68ib",
    "outputId": "cc131011-6dde-4050-eefe-a387914beaa2"
   },
   "outputs": [],
   "source": [
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome(\"ChromeDriver_Path/chromedriver\")\n",
    "# Opening the url we have just defined in our browser\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113000\n"
     ]
    }
   ],
   "source": [
    "#We find how many jobs are offered.\n",
    "jobs_num = driver.find_element(By.CSS_SELECTOR,\"h1>span\").get_attribute(\"innerText\")\n",
    "if len(jobs_num.split(',')) > 1:\n",
    "    jobs_num = int(jobs_num.split(',')[0])*1000\n",
    "else:\n",
    "    jobs_num = int(jobs_num)\n",
    "\n",
    "jobs_num   = int(jobs_num)\n",
    "print(jobs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the numbers of jobs needed: 102\n"
     ]
    }
   ],
   "source": [
    "numbers = input(\"Enter the numbers of jobs needed: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a while loop to browse all jobs. \n",
    "numbers = int(numbers)\n",
    "i = 2\n",
    "while i <= int(numbers/2)+1:\n",
    "    #We keep scrollind down to the end of the view.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    i = i + 1\n",
    "    #print(\"Current at: \", i, \"Percentage at: \", ((i+1)/(int(numbers/2)+1))*100, \"%\",end=\"\\r\")\n",
    "    try:\n",
    "        #We try to click on the load more results buttons in case it is already displayed.\n",
    "        infinite_scroller_button = driver.find_element(By.XPATH, \".//button[@aria-label='Load more results']\")\n",
    "        infinite_scroller_button.click()\n",
    "        time.sleep(0.1)\n",
    "    except:\n",
    "        #If there is no button, there will be an error, so we keep scrolling down.\n",
    "        time.sleep(0.1)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amicus</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Applied Machine Learning Scientist</td>\n",
       "      <td>Liminal</td>\n",
       "      <td>Emeryville, CA</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/applied-mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Shtudy</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Russell Tobin</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Internship: Machine Learning for Electric Desi...</td>\n",
       "      <td>Mitsubishi Electric Research Laboratories</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/internship-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Machine Learning Developer</td>\n",
       "      <td>SynergisticIT</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>100% Remote Anomaly Detection Machine Learning...</td>\n",
       "      <td>Summit Human Capital</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/100%25-remo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job Title  \\\n",
       "0              Data Scientist (Deep Learning), Peacock   \n",
       "1                                       Data Scientist   \n",
       "2                   Applied Machine Learning Scientist   \n",
       "3                                Junior Data Scientist   \n",
       "4                            Machine Learning Engineer   \n",
       "..                                                 ...   \n",
       "345                          Machine Learning Engineer   \n",
       "346  Internship: Machine Learning for Electric Desi...   \n",
       "347                         Machine Learning Developer   \n",
       "348  100% Remote Anomaly Detection Machine Learning...   \n",
       "349                                     Data Scientist   \n",
       "\n",
       "                                       Company        Location        Date  \\\n",
       "0                                      Peacock    New York, NY  2022-12-06   \n",
       "1                                       Amicus    New York, NY  2022-12-06   \n",
       "2                                      Liminal  Emeryville, CA  2022-12-08   \n",
       "3                                      ClearML   United States  2022-12-16   \n",
       "4                                       Shtudy  Washington, DC  2022-12-08   \n",
       "..                                         ...             ...         ...   \n",
       "345                              Russell Tobin   United States  2022-12-12   \n",
       "346  Mitsubishi Electric Research Laboratories   Cambridge, MA  2022-12-02   \n",
       "347                              SynergisticIT     Raleigh, NC  2022-12-08   \n",
       "348                       Summit Human Capital   Rockville, MD  2022-11-18   \n",
       "349                             Insight Global   United States  2022-12-14   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "1    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "2    https://www.linkedin.com/jobs/view/applied-mac...  \n",
       "3    https://www.linkedin.com/jobs/view/junior-data...  \n",
       "4    https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "..                                                 ...  \n",
       "345  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "346  https://www.linkedin.com/jobs/view/internship-...  \n",
       "347  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "348  https://www.linkedin.com/jobs/view/100%25-remo...  \n",
       "349  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We get a list containing all jobs that we have found.\n",
    "job_lists = driver.find_element(By.CLASS_NAME,\"jobs-search__results-list\")\n",
    "jobs = job_lists.find_elements(By.TAG_NAME,\"li\") # return a list\n",
    "\n",
    "#We declare void list to keep track of all obtaind data.\n",
    "job_title_list = []\n",
    "company_name_list = []\n",
    "location_list = []\n",
    "date_list = []\n",
    "job_link_list = []\n",
    "\n",
    "#We loof over every job and obtain all the wanted info.\n",
    "for job in jobs:\n",
    "    #job_title\n",
    "    job_title = job.find_element(By.CSS_SELECTOR,\"h3\").get_attribute(\"innerText\")\n",
    "    job_title_list.append(job_title)\n",
    "    \n",
    "    #company_name\n",
    "    company_name = job.find_element(By.CSS_SELECTOR,\"h4\").get_attribute(\"innerText\")\n",
    "    company_name_list.append(company_name)\n",
    "    \n",
    "    #location\n",
    "    location = job.find_element(By.CSS_SELECTOR,\"div>div>span\").get_attribute(\"innerText\")\n",
    "    location_list.append(location)\n",
    "    \n",
    "    #date\n",
    "    date = job.find_element(By.CSS_SELECTOR,\"div>div>time\").get_attribute(\"datetime\")\n",
    "    date_list.append(date)\n",
    "    \n",
    "    #job_link\n",
    "    job_link = job.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"href\")\n",
    "    job_link_list.append(job_link)\n",
    "\n",
    "jobs_df = pd.DataFrame({'Job Title': job_title_list,\n",
    "              'Company': company_name_list,\n",
    "              'Location': location_list,\n",
    "              'Date': date_list,\n",
    "              'Link': job_link_list\n",
    "            })\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "jobs_df.to_csv('Sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
